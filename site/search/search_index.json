{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. - Home: AdHoc_Trader -index.html.md - Deno.json: deno.md - Component.json: component.md - eslint.config: eslint.config.md - import_map: import_map.md - package: package.md - package-lock: package-lock.md - postcss.config: postcss.config.md - tailwind.config: tailwind.config.js.md - tailwind.config: tailwind.config.ts.md - tsconfig.node: tsconfig.node.md - vite-env.d.ts: vite-env.d.ts.md - vite.config: vite.config.md - Dependencies: - dependencies: dependencies.md - VSCode - settings.json: settings.json.md - ml_pipeline: - .env: - VSCode: - settings.json.md - historical_ingestion - alpha_vantage: alpha_vantage.md - config: config.md - ingestion_historical: ingestion_historical.md - run_pipeline: run_pipeline.md - supabase_client: supabase_client.md - utils: utils.md - src: - dl: - lstm_model: lstm_model.md - ml: - data_fetcher: data_fetcher.md - feature_engineering: feature_engineering.md - pedictor: predictor.md - supabase_uploader: supabase_uplder.md - training_model: training_model.md - tests: - test_normalization: test_normalization.md - requirements: requirements.md","title":"Home"},{"location":"index.html#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"index.html#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"index.html#project-layout","text":"mkdocs.yml # The configuration file. - Home: AdHoc_Trader -index.html.md - Deno.json: deno.md - Component.json: component.md - eslint.config: eslint.config.md - import_map: import_map.md - package: package.md - package-lock: package-lock.md - postcss.config: postcss.config.md - tailwind.config: tailwind.config.js.md - tailwind.config: tailwind.config.ts.md - tsconfig.node: tsconfig.node.md - vite-env.d.ts: vite-env.d.ts.md - vite.config: vite.config.md - Dependencies: - dependencies: dependencies.md - VSCode - settings.json: settings.json.md - ml_pipeline: - .env: - VSCode: - settings.json.md - historical_ingestion - alpha_vantage: alpha_vantage.md - config: config.md - ingestion_historical: ingestion_historical.md - run_pipeline: run_pipeline.md - supabase_client: supabase_client.md - utils: utils.md - src: - dl: - lstm_model: lstm_model.md - ml: - data_fetcher: data_fetcher.md - feature_engineering: feature_engineering.md - pedictor: predictor.md - supabase_uploader: supabase_uplder.md - training_model: training_model.md - tests: - test_normalization: test_normalization.md - requirements: requirements.md","title":"Project layout"},{"location":"component.json.html","text":"Component Configuration ('shadcn.config') component.JSON file UI Configuration ( shadcn.config.json ) \u00b6 This JSON configuration controls the UI setup and tooling options. Overview \u00b6 Schema : Defines the JSON schema for validation and tooling support. Style : The default UI style/theme used. React Server Components (RSC) : Disabled ( false ). TypeScript JSX (TSX) : Enabled ( true ). Tailwind CSS : Configuration settings including: Tailwind config file: tailwind.config.ts CSS entry file: src/index.css Base color palette: slate Use of CSS variables: enabled CSS class prefix: none Aliases \u00b6 Defines path aliases for cleaner imports: | Alias | Maps To | |-------------|-------------------| | components | @/components | | utils | @/lib/utils | | ui | @/components/ui | | lib | @/lib | | hooks | @/hooks | Purpose \u00b6 This config helps streamline component and utility imports in the project, manages Tailwind CSS integration, and sets core UI framework options. site_name: AdHoc_Trader nav: - Home: - index: index.html.md - Deno.json: deno.md - Component.json: component.md - eslint.config: eslint.config.md - import_map: import_map.md - package: package.md - package-lock: package-lock.md - postcss.config: postcss.config.md - tailwind.config.js: tailwind.config.js.md - tailwind.config.ts: tailwind.config.ts.md - tsconfig.node: tsconfig.node.md - vite-env.d.ts: vite-env.d.ts.md - vite.config: vite.config.md Dependencies: dependencies: dependencies.md VSCode: settings.json: settings.json.md ml_pipeline: .env: .env.md VSCode: settings.json: settings.json.md historical_ingestion: alpha_vantage: alpha_vantage.md config: config.md ingestion_historical: ingestion_historical.md run_pipeline: run_pipeline.md supabase_client: supabase_client.md utils: utils.md src: dl: lstm_model: lstm_model.md ml: data_fetcher: data_fetcher.md feature_engineering: feature_engineering.md predictor: predictor.md supabase_uploader: supabase_uploader.md training_model: training_model.md tests: test_normalization: test_normalization.md venv: requirements: requirements.md","title":"Component.json"},{"location":"component.json.html#ui-configuration-shadcnconfigjson","text":"This JSON configuration controls the UI setup and tooling options.","title":"UI Configuration (shadcn.config.json)"},{"location":"component.json.html#overview","text":"Schema : Defines the JSON schema for validation and tooling support. Style : The default UI style/theme used. React Server Components (RSC) : Disabled ( false ). TypeScript JSX (TSX) : Enabled ( true ). Tailwind CSS : Configuration settings including: Tailwind config file: tailwind.config.ts CSS entry file: src/index.css Base color palette: slate Use of CSS variables: enabled CSS class prefix: none","title":"Overview"},{"location":"component.json.html#aliases","text":"Defines path aliases for cleaner imports: | Alias | Maps To | |-------------|-------------------| | components | @/components | | utils | @/lib/utils | | ui | @/components/ui | | lib | @/lib | | hooks | @/hooks |","title":"Aliases"},{"location":"component.json.html#purpose","text":"This config helps streamline component and utility imports in the project, manages Tailwind CSS integration, and sets core UI framework options. site_name: AdHoc_Trader nav: - Home: - index: index.html.md - Deno.json: deno.md - Component.json: component.md - eslint.config: eslint.config.md - import_map: import_map.md - package: package.md - package-lock: package-lock.md - postcss.config: postcss.config.md - tailwind.config.js: tailwind.config.js.md - tailwind.config.ts: tailwind.config.ts.md - tsconfig.node: tsconfig.node.md - vite-env.d.ts: vite-env.d.ts.md - vite.config: vite.config.md Dependencies: dependencies: dependencies.md VSCode: settings.json: settings.json.md ml_pipeline: .env: .env.md VSCode: settings.json: settings.json.md historical_ingestion: alpha_vantage: alpha_vantage.md config: config.md ingestion_historical: ingestion_historical.md run_pipeline: run_pipeline.md supabase_client: supabase_client.md utils: utils.md src: dl: lstm_model: lstm_model.md ml: data_fetcher: data_fetcher.md feature_engineering: feature_engineering.md predictor: predictor.md supabase_uploader: supabase_uploader.md training_model: training_model.md tests: test_normalization: test_normalization.md venv: requirements: requirements.md","title":"Purpose"},{"location":"deno.json.html","text":"Deno Configuration ( deno.json ) \u00b6 This file configures the Deno runtime and compiler options for the project. Contents \u00b6 ```json { \"compilerOptions\": { \"lib\": [\"deno.ns\", \"deno.unstable\", \"dom\"] }, \"importMap\": \"./import_map.json\" }","title":"Deno.Config"},{"location":"deno.json.html#deno-configuration-denojson","text":"This file configures the Deno runtime and compiler options for the project.","title":"Deno Configuration (deno.json)"},{"location":"deno.json.html#contents","text":"```json { \"compilerOptions\": { \"lib\": [\"deno.ns\", \"deno.unstable\", \"dom\"] }, \"importMap\": \"./import_map.json\" }","title":"Contents"},{"location":"eslint.config.html","text":"ESLint Configuration ( eslint.config.js ) \u00b6 This file sets up ESLint with TypeScript and React support tailored for this project. Highlights \u00b6 Core ESLint config: Uses @eslint/js recommended rules. TypeScript ESLint integration: Applies TypeScript-specific linting with typescript-eslint . File targeting: Applies only to .ts and .tsx files. Environment: ECMAScript 2020 and browser globals enabled. Plugins: react-hooks : Enforces rules of React hooks usage. react-refresh : Supports React Fast Refresh for hot reloading during development. Custom rules: React hooks recommended rules enabled. Warns if non-components are exported during React refresh except constant exports. Turns off the @typescript-eslint/no-unused-vars rule. Ignored files \u00b6 All files in the dist directory are ignored from linting. Purpose \u00b6 This configuration ensures clean, consistent, and error-free code while supporting TypeScript and React-specific features, improving development experience with hot reloading.","title":"ESLint Config"},{"location":"eslint.config.html#eslint-configuration-eslintconfigjs","text":"This file sets up ESLint with TypeScript and React support tailored for this project.","title":"ESLint Configuration (eslint.config.js)"},{"location":"eslint.config.html#highlights","text":"Core ESLint config: Uses @eslint/js recommended rules. TypeScript ESLint integration: Applies TypeScript-specific linting with typescript-eslint . File targeting: Applies only to .ts and .tsx files. Environment: ECMAScript 2020 and browser globals enabled. Plugins: react-hooks : Enforces rules of React hooks usage. react-refresh : Supports React Fast Refresh for hot reloading during development. Custom rules: React hooks recommended rules enabled. Warns if non-components are exported during React refresh except constant exports. Turns off the @typescript-eslint/no-unused-vars rule.","title":"Highlights"},{"location":"eslint.config.html#ignored-files","text":"All files in the dist directory are ignored from linting.","title":"Ignored files"},{"location":"eslint.config.html#purpose","text":"This configuration ensures clean, consistent, and error-free code while supporting TypeScript and React-specific features, improving development experience with hot reloading.","title":"Purpose"},{"location":"import_map.html","text":"Import Map \u00b6 The import_map.json file is used to define module specifier aliases for the Deno runtime. This allows you to simplify and standardize your imports across the project without hardcoding long URLs everywhere. File: import_map.json \u00b6 ```json { \"imports\": { \"supabase\": \"https://esm.sh/@supabase/supabase-js@2.39.5\" } }","title":"Import Map"},{"location":"import_map.html#import-map","text":"The import_map.json file is used to define module specifier aliases for the Deno runtime. This allows you to simplify and standardize your imports across the project without hardcoding long URLs everywhere.","title":"Import Map"},{"location":"import_map.html#file-import_mapjson","text":"```json { \"imports\": { \"supabase\": \"https://esm.sh/@supabase/supabase-js@2.39.5\" } }","title":"File: import_map.json"},{"location":"index.html.html","text":"HTML Entry Point - index.html \u00b6 This is the main HTML entry point for the AdHoc_Trader web application. It\u2019s structured to load the React-based frontend, define essential metadata, and support SEO and social sharing features. Location \u00b6 Root of the project: /index.html \ud83e\udde0 Key Elements \u00b6 <head> \u00b6 Meta Charset : UTF-8 encoding for broad character support. Viewport : Optimized for mobile responsiveness. Title : ADH0C_Trading \u2014 shown in the browser tab. Description : Helps with SEO, summarizing your app. Author : \"Famous.ai\" credited as the creator. Favicon : /placeholder.svg used as tab icon. SEO & Social Tags \u00b6 Open Graph ( og: ) : Used by social media previews (e.g., Facebook, LinkedIn). og:image : /og.jpg used for link previews. Twitter Card : Supports large image preview on shared links. Includes Twitter handle and image metadata. <body> \u00b6 <div id=\"root\"></div> : This is where the React app is mounted by main.tsx . Main Script : ```html","title":"index.html"},{"location":"index.html.html#html-entry-point-indexhtml","text":"This is the main HTML entry point for the AdHoc_Trader web application. It\u2019s structured to load the React-based frontend, define essential metadata, and support SEO and social sharing features.","title":"HTML Entry Point - index.html"},{"location":"index.html.html#location","text":"Root of the project: /index.html","title":"Location"},{"location":"index.html.html#key-elements","text":"","title":"\ud83e\udde0 Key Elements"},{"location":"index.html.html#head","text":"Meta Charset : UTF-8 encoding for broad character support. Viewport : Optimized for mobile responsiveness. Title : ADH0C_Trading \u2014 shown in the browser tab. Description : Helps with SEO, summarizing your app. Author : \"Famous.ai\" credited as the creator. Favicon : /placeholder.svg used as tab icon.","title":"&lt;head&gt;"},{"location":"index.html.html#seo-social-tags","text":"Open Graph ( og: ) : Used by social media previews (e.g., Facebook, LinkedIn). og:image : /og.jpg used for link previews. Twitter Card : Supports large image preview on shared links. Includes Twitter handle and image metadata.","title":"SEO &amp; Social Tags"},{"location":"index.html.html#body","text":"<div id=\"root\"></div> : This is where the React app is mounted by main.tsx . Main Script : ```html","title":"&lt;body&gt;"},{"location":"mermaid.html","text":"","title":"Mermaid"},{"location":"package-lock.html","text":"Dependency Management \u00b6 This project uses npm for package management. All dependencies are defined in package.json , and locked versions are stored in package-lock.json to ensure consistent installs. Run the following to install all required dependencies: ```bash npm install npm list --depth=0 > dependencies.txt","title":"Package-lock"},{"location":"package-lock.html#dependency-management","text":"This project uses npm for package management. All dependencies are defined in package.json , and locked versions are stored in package-lock.json to ensure consistent installs. Run the following to install all required dependencies: ```bash npm install npm list --depth=0 > dependencies.txt","title":"Dependency Management"},{"location":"package.html","text":"package.json Overview \u00b6 The package.json file defines your project metadata, dependencies, development tools, and scripts. Project Metadata \u00b6 name: vite_react_shadcn_ts version: 0.0.0 private: true (not published publicly) type: module (ES Modules enabled) Scripts \u00b6 These are the npm scripts you can run: Script Description dev Start development server ( vite ) build Build production assets build:dev Build with development mode lint Run ESLint to check code quality preview Preview the production build Run scripts like this: ```bash npm run dev Dependencies Your runtime dependencies include: UI & React ecosystem: react ^18.3.1, react-dom ^18.3.1 @radix-ui/* (various UI primitives) shadcn/ui components (implied by Radix usage) lucide-react icons clsx, class-variance-authority for class management cmdk command palette recharts charting Backend / Data: @supabase/supabase-js ^2.49.4 and auth helpers axios for HTTP requests uuid for unique IDs zod for schema validation Utility: date-fns for date utilities marked markdown parser react-hook-form and resolver for forms react-router-dom for routing react-day-picker for date picking UI sonner for notifications tailwind-merge & tailwindcss-animate for CSS utilities vaul (likely for state or storage)","title":"Package"},{"location":"package.html#packagejson-overview","text":"The package.json file defines your project metadata, dependencies, development tools, and scripts.","title":"package.json Overview"},{"location":"package.html#project-metadata","text":"name: vite_react_shadcn_ts version: 0.0.0 private: true (not published publicly) type: module (ES Modules enabled)","title":"Project Metadata"},{"location":"package.html#scripts","text":"These are the npm scripts you can run: Script Description dev Start development server ( vite ) build Build production assets build:dev Build with development mode lint Run ESLint to check code quality preview Preview the production build Run scripts like this: ```bash npm run dev Dependencies Your runtime dependencies include: UI & React ecosystem: react ^18.3.1, react-dom ^18.3.1 @radix-ui/* (various UI primitives) shadcn/ui components (implied by Radix usage) lucide-react icons clsx, class-variance-authority for class management cmdk command palette recharts charting Backend / Data: @supabase/supabase-js ^2.49.4 and auth helpers axios for HTTP requests uuid for unique IDs zod for schema validation Utility: date-fns for date utilities marked markdown parser react-hook-form and resolver for forms react-router-dom for routing react-day-picker for date picking UI sonner for notifications tailwind-merge & tailwindcss-animate for CSS utilities vaul (likely for state or storage)","title":"Scripts"},{"location":"postcss.config.html","text":"PostCSS Configuration ( postcss.config.js ) \u00b6 This configuration file sets up PostCSS plugins for the project. Plugins Used \u00b6 tailwindcss : Enables Tailwind CSS processing. autoprefixer : Adds vendor prefixes automatically for better browser compatibility. Content of postcss.config.js \u00b6 ```js export default { plugins: { tailwindcss: {}, autoprefixer: {}, }, } Purpose: TailwindCSS uses PostCSS to process utility classes and generate CSS. Autoprefixer ensures that CSS works correctly across different browsers by adding necessary vendor prefixes. How to Use This file is automatically detected by build tools like Vite when running the development server or building the project.","title":"PostCSS Config"},{"location":"postcss.config.html#postcss-configuration-postcssconfigjs","text":"This configuration file sets up PostCSS plugins for the project.","title":"PostCSS Configuration (postcss.config.js)"},{"location":"postcss.config.html#plugins-used","text":"tailwindcss : Enables Tailwind CSS processing. autoprefixer : Adds vendor prefixes automatically for better browser compatibility.","title":"Plugins Used"},{"location":"postcss.config.html#content-of-postcssconfigjs","text":"```js export default { plugins: { tailwindcss: {}, autoprefixer: {}, }, } Purpose: TailwindCSS uses PostCSS to process utility classes and generate CSS. Autoprefixer ensures that CSS works correctly across different browsers by adding necessary vendor prefixes. How to Use This file is automatically detected by build tools like Vite when running the development server or building the project.","title":"Content of postcss.config.js"},{"location":"tailwind.config.js.html","text":"Tailwind CSS Configuration ( tailwind.config.ts ) \u00b6 This file configures Tailwind CSS for your project. Content \u00b6 Specifies the files to scan for class names: ```ts content: [ \"./index.html\", \"./src/* / .{js,ts,jsx,tsx}\", ], Extends the default theme with custom colors and border radius using CSS variables. Defines custom CSS variables for light and dark modes. Adds the @tailwindcss/typography plugin for better prose styling. Uses a custom plugin to set CSS variables on :root for light and .dark for dark mode themes. Key Features Custom Colors: Colors are defined via CSS variables for dynamic theming. Dark Mode Support: Dark mode variables override colors when .dark class is applied. Border Radius: Uses a CSS variable for consistent rounded corners. Typography Plugin: Enhances styling of rich text content like articles or markdown. Usage Notes The custom plugin defines color schemes in HSL with CSS variables, allowing easy theme switching. Make sure your app toggles the .dark class on the or element to activate dark mode. This config works seamlessly with Tailwind\u2019s JIT mode for efficient CSS generation.","title":"Tailwind Config JS"},{"location":"tailwind.config.js.html#tailwind-css-configuration-tailwindconfigts","text":"This file configures Tailwind CSS for your project.","title":"Tailwind CSS Configuration (tailwind.config.ts)"},{"location":"tailwind.config.js.html#content","text":"Specifies the files to scan for class names: ```ts content: [ \"./index.html\", \"./src/* / .{js,ts,jsx,tsx}\", ], Extends the default theme with custom colors and border radius using CSS variables. Defines custom CSS variables for light and dark modes. Adds the @tailwindcss/typography plugin for better prose styling. Uses a custom plugin to set CSS variables on :root for light and .dark for dark mode themes. Key Features Custom Colors: Colors are defined via CSS variables for dynamic theming. Dark Mode Support: Dark mode variables override colors when .dark class is applied. Border Radius: Uses a CSS variable for consistent rounded corners. Typography Plugin: Enhances styling of rich text content like articles or markdown. Usage Notes The custom plugin defines color schemes in HSL with CSS variables, allowing easy theme switching. Make sure your app toggles the .dark class on the or element to activate dark mode. This config works seamlessly with Tailwind\u2019s JIT mode for efficient CSS generation.","title":"Content"},{"location":"tailwind.config.ts.html","text":"Tailwind CSS Configuration ( tailwind.config.ts ) \u00b6 This file configures Tailwind CSS for your project, including custom themes, colors, fonts, animations, and plugins. Dark Mode \u00b6 ```ts darkMode: [\"class\"], Enables dark mode toggling via a .dark class. Content Paths ts Copy Edit content: [ \"./pages/ /*.{ts,tsx}\", \"./components/ / .{ts,tsx}\", \"./app/ / .{ts,tsx}\", \"./src/* / .{ts,tsx}\", ], Specifies files Tailwind should scan for class names to generate styles. Theme Customizations Container ts Copy Edit container: { center: true, padding: '2rem', screens: { '2xl': '1400px' }, }, Centers container with padding and custom max width for large screens. Extended Colors Uses CSS variables (--primary, --background, etc.) for colors, supporting theming. Includes specialized color groups for UI elements like sidebar, popover, card, etc. Fonts ts Copy Edit fontFamily: { mono: ['JetBrains Mono', 'monospace'], sans: ['Inter', 'sans-serif'], }, Defines monospace and sans-serif fonts. Border Radius Customizes sizes for lg, md, and sm radii using CSS variables. Animations & Keyframes Defines keyframes and animations for accordion open/close, fade-in, and slide-in effects. Typography ts Copy Edit typography: { DEFAULT: { css: { maxWidth: 'none' } } } Customizes default typography styles. Plugins tailwindcss-animate: Adds utility classes for animations. @tailwindcss/typography: Provides prose classes for rich text formatting. Summary This config gives you a fully customizable, theme-aware Tailwind setup with dark mode support, smooth animations, and a clean typography system \u2014 all ready to power a modern React + TypeScript UI.","title":"Tailwind Config"},{"location":"tailwind.config.ts.html#tailwind-css-configuration-tailwindconfigts","text":"This file configures Tailwind CSS for your project, including custom themes, colors, fonts, animations, and plugins.","title":"Tailwind CSS Configuration (tailwind.config.ts)"},{"location":"tailwind.config.ts.html#dark-mode","text":"```ts darkMode: [\"class\"], Enables dark mode toggling via a .dark class. Content Paths ts Copy Edit content: [ \"./pages/ /*.{ts,tsx}\", \"./components/ / .{ts,tsx}\", \"./app/ / .{ts,tsx}\", \"./src/* / .{ts,tsx}\", ], Specifies files Tailwind should scan for class names to generate styles. Theme Customizations Container ts Copy Edit container: { center: true, padding: '2rem', screens: { '2xl': '1400px' }, }, Centers container with padding and custom max width for large screens. Extended Colors Uses CSS variables (--primary, --background, etc.) for colors, supporting theming. Includes specialized color groups for UI elements like sidebar, popover, card, etc. Fonts ts Copy Edit fontFamily: { mono: ['JetBrains Mono', 'monospace'], sans: ['Inter', 'sans-serif'], }, Defines monospace and sans-serif fonts. Border Radius Customizes sizes for lg, md, and sm radii using CSS variables. Animations & Keyframes Defines keyframes and animations for accordion open/close, fade-in, and slide-in effects. Typography ts Copy Edit typography: { DEFAULT: { css: { maxWidth: 'none' } } } Customizes default typography styles. Plugins tailwindcss-animate: Adds utility classes for animations. @tailwindcss/typography: Provides prose classes for rich text formatting. Summary This config gives you a fully customizable, theme-aware Tailwind setup with dark mode support, smooth animations, and a clean typography system \u2014 all ready to power a modern React + TypeScript UI.","title":"Dark Mode"},{"location":"tsconfig.node.html","text":"TypeScript Configuration ( tsconfig.json ) \u00b6 This file configures the TypeScript compiler options for your project. Key Compiler Options \u00b6 target: ES2020 Compiles TypeScript to ECMAScript 2020 standard. lib: [ \"ES2020\" ] Includes ES2020 built-in type definitions. module: CommonJS Uses CommonJS module system. composite: true Enables project references and incremental builds. skipLibCheck: true Skips type checking of declaration files for faster compilation. emitDeclarationOnly: true Only emits .d.ts declaration files without JavaScript output. strict: true Enables all strict type-checking options. noUnusedLocals: false Allows unused local variables without error. noUnusedParameters: false Allows unused function parameters without error. Paths and Base URL \u00b6 baseUrl: . Sets the base directory for module resolution. paths: ```json { \"@/ \": [\"./src/ \"] } [\"src/ /*.ts\", \"src/ /*.d.ts\", \"vite.config.ts\"] Usage Notes This config focuses on generating type declaration files only (emitDeclarationOnly), so your build system must handle JS compilation separately. The paths setting simplifies imports by using @/ as an alias for the src directory. Strict mode helps catch common bugs by enforcing rigorous type checks.","title":"TS Config Node"},{"location":"tsconfig.node.html#typescript-configuration-tsconfigjson","text":"This file configures the TypeScript compiler options for your project.","title":"TypeScript Configuration (tsconfig.json)"},{"location":"tsconfig.node.html#key-compiler-options","text":"target: ES2020 Compiles TypeScript to ECMAScript 2020 standard. lib: [ \"ES2020\" ] Includes ES2020 built-in type definitions. module: CommonJS Uses CommonJS module system. composite: true Enables project references and incremental builds. skipLibCheck: true Skips type checking of declaration files for faster compilation. emitDeclarationOnly: true Only emits .d.ts declaration files without JavaScript output. strict: true Enables all strict type-checking options. noUnusedLocals: false Allows unused local variables without error. noUnusedParameters: false Allows unused function parameters without error.","title":"Key Compiler Options"},{"location":"tsconfig.node.html#paths-and-base-url","text":"baseUrl: . Sets the base directory for module resolution. paths: ```json { \"@/ \": [\"./src/ \"] } [\"src/ /*.ts\", \"src/ /*.d.ts\", \"vite.config.ts\"] Usage Notes This config focuses on generating type declaration files only (emitDeclarationOnly), so your build system must handle JS compilation separately. The paths setting simplifies imports by using @/ as an alias for the src directory. Strict mode helps catch common bugs by enforcing rigorous type checks.","title":"Paths and Base URL"},{"location":"vite-env.d.ts.html","text":"Vite Environment Type Declarations ( vite-env.d.ts ) \u00b6 This file provides TypeScript type definitions for environment variables used in the Vite project. Purpose \u00b6 Extends the TypeScript typings for the import.meta.env object. Ensures TypeScript understands the shape of your environment variables. Enables type safety and autocompletion when accessing environment variables. Defined Environment Variables \u00b6 ```ts interface ImportMetaEnv { readonly VITE_SUPABASE_URL: string; readonly VITE_SUPABASE_ANON_KEY: string; readonly VITE_ALPACA_API_KEY: string; readonly VITE_ALPACA_SECRET_KEY: string; readonly VITE_ALPACA_BASE_URL: string; // Add more vars here as needed } Notes Make sure all these variables are defined in your .env or environment configuration. Prefix environment variables with VITE_ so Vite exposes them to the client-side code.","title":"Vite Env Types"},{"location":"vite-env.d.ts.html#vite-environment-type-declarations-vite-envdts","text":"This file provides TypeScript type definitions for environment variables used in the Vite project.","title":"Vite Environment Type Declarations (vite-env.d.ts)"},{"location":"vite-env.d.ts.html#purpose","text":"Extends the TypeScript typings for the import.meta.env object. Ensures TypeScript understands the shape of your environment variables. Enables type safety and autocompletion when accessing environment variables.","title":"Purpose"},{"location":"vite-env.d.ts.html#defined-environment-variables","text":"```ts interface ImportMetaEnv { readonly VITE_SUPABASE_URL: string; readonly VITE_SUPABASE_ANON_KEY: string; readonly VITE_ALPACA_API_KEY: string; readonly VITE_ALPACA_SECRET_KEY: string; readonly VITE_ALPACA_BASE_URL: string; // Add more vars here as needed } Notes Make sure all these variables are defined in your .env or environment configuration. Prefix environment variables with VITE_ so Vite exposes them to the client-side code.","title":"Defined Environment Variables"},{"location":"vite.config.html","text":"Vite Configuration ( vite.config.ts ) \u00b6 This file configures the Vite build tool and development server for the project. Key Configuration Sections \u00b6 Server \u00b6 ```ts server: { host: \"::\", port: 8080, watch: { ignored: [' /ml_pipeline/ '], // Ignore this directory to prevent EIO crash }, historyApiFallback: true, }, host: \"::\" \u2014 Accepts connections on all IPv6 addresses. port: 8080 \u2014 Development server runs on port 8080. watch.ignored \u2014 Prevents Vite from watching the ml_pipeline directory to avoid errors. historyApiFallback: true \u2014 Supports SPA routing by redirecting unknown routes to index. Defines environment variables for use in the client code. Uses JSON.stringify to inject the variables safely at build time. Usage Notes The config supports React with fast SWC compilation. Alias paths make your imports cleaner and easier to maintain. Environment variables prefixed with NEXT_PUBLIC_ are exposed to client code. Ignoring large or frequently changing directories during watch avoids crashes and improves performance.","title":"Vite Config"},{"location":"vite.config.html#vite-configuration-viteconfigts","text":"This file configures the Vite build tool and development server for the project.","title":"Vite Configuration (vite.config.ts)"},{"location":"vite.config.html#key-configuration-sections","text":"","title":"Key Configuration Sections"},{"location":"vite.config.html#server","text":"```ts server: { host: \"::\", port: 8080, watch: { ignored: [' /ml_pipeline/ '], // Ignore this directory to prevent EIO crash }, historyApiFallback: true, }, host: \"::\" \u2014 Accepts connections on all IPv6 addresses. port: 8080 \u2014 Development server runs on port 8080. watch.ignored \u2014 Prevents Vite from watching the ml_pipeline directory to avoid errors. historyApiFallback: true \u2014 Supports SPA routing by redirecting unknown routes to index. Defines environment variables for use in the client code. Uses JSON.stringify to inject the variables safely at build time. Usage Notes The config supports React with fast SWC compilation. Alias paths make your imports cleaner and easier to maintain. Environment variables prefixed with NEXT_PUBLIC_ are exposed to client code. Ignoring large or frequently changing directories during watch avoids crashes and improves performance.","title":"Server"},{"location":"VSCode/settings.json.html","text":"VSCode Workspace Settings \u00b6 This file configures editor and tooling preferences tailored to your multi-language project setup. TypeScript & Deno Configuration \u00b6 ```json \"typescript.tsdk\": \"node_modules\\typescript\\lib\", \"deno.enable\": true, \"deno.lint\": true, \"deno.unstable\": true, \"deno.importMap\": \"./import_map.json\", \"files.associations\": { \" /supabase/functions/ /*.ts\": \"typescript\" } Uses local TypeScript SDK from node_modules. Enables Deno integration with linting and unstable APIs. Specifies import map for Deno (import_map.json). Associates .ts files under supabase/functions as TypeScript for better tooling. Python / Machine Learning Backend json Copy Edit \"python.analysis.extraPaths\": [\"./ml_pipeline\"], \"python.envFile\": \"${workspaceFolder}/.env\", \"python.linting.enabled\": true, \"python.linting.pylintEnabled\": true, \"python.linting.lintOnSave\": true, \"python.linting.pylintPath\": \"${workspaceFolder}/venv/Scripts/pylint.exe\", \"python.defaultInterpreterPath\": \"${workspaceFolder}/venv/Scripts/python.exe\", Adds ml_pipeline folder to Python analysis paths. Uses project .env file for environment variables. Enables linting with pylint on save. Explicitly points to Python interpreter and pylint inside the project virtual environment. Editor Enhancements json Copy Edit \"editor.defaultFormatter\": \"ms-python.black-formatter\", \"editor.formatOnSave\": true, \"editor.minimap.enabled\": false, \"diffEditor.codeLens\": true, \"workbench.settings.useSplitJSON\": true, \"workbench.editor.enablePreview\": false Sets black as default formatter for Python. Automatically formats on save. Disables minimap for cleaner view. Enables code lens in diff editor. Uses split JSON view for settings. Disables preview mode in editors for better tab control. Summary These workspace settings ensure smooth multi-language development with Deno, TypeScript, Python, and enhanced editor experience, all configured to your project structure and workflow.","title":"VSCode Settings"},{"location":"VSCode/settings.json.html#vscode-workspace-settings","text":"This file configures editor and tooling preferences tailored to your multi-language project setup.","title":"VSCode Workspace Settings"},{"location":"VSCode/settings.json.html#typescript-deno-configuration","text":"```json \"typescript.tsdk\": \"node_modules\\typescript\\lib\", \"deno.enable\": true, \"deno.lint\": true, \"deno.unstable\": true, \"deno.importMap\": \"./import_map.json\", \"files.associations\": { \" /supabase/functions/ /*.ts\": \"typescript\" } Uses local TypeScript SDK from node_modules. Enables Deno integration with linting and unstable APIs. Specifies import map for Deno (import_map.json). Associates .ts files under supabase/functions as TypeScript for better tooling. Python / Machine Learning Backend json Copy Edit \"python.analysis.extraPaths\": [\"./ml_pipeline\"], \"python.envFile\": \"${workspaceFolder}/.env\", \"python.linting.enabled\": true, \"python.linting.pylintEnabled\": true, \"python.linting.lintOnSave\": true, \"python.linting.pylintPath\": \"${workspaceFolder}/venv/Scripts/pylint.exe\", \"python.defaultInterpreterPath\": \"${workspaceFolder}/venv/Scripts/python.exe\", Adds ml_pipeline folder to Python analysis paths. Uses project .env file for environment variables. Enables linting with pylint on save. Explicitly points to Python interpreter and pylint inside the project virtual environment. Editor Enhancements json Copy Edit \"editor.defaultFormatter\": \"ms-python.black-formatter\", \"editor.formatOnSave\": true, \"editor.minimap.enabled\": false, \"diffEditor.codeLens\": true, \"workbench.settings.useSplitJSON\": true, \"workbench.editor.enablePreview\": false Sets black as default formatter for Python. Automatically formats on save. Disables minimap for cleaner view. Enables code lens in diff editor. Uses split JSON view for settings. Disables preview mode in editors for better tab control. Summary These workspace settings ensure smooth multi-language development with Deno, TypeScript, Python, and enhanced editor experience, all configured to your project structure and workflow.","title":"TypeScript &amp; Deno Configuration"},{"location":"dependencies/dependencies.html","text":"Dependencies \u00b6 This project uses Node.js and npm for package and build management. Core Dependencies \u00b6 React \u2014 Frontend library for building UI components. Vite \u2014 Modern frontend build tool. Tailwind CSS \u2014 Utility-first CSS framework for styling. shadcn/ui \u2014 Component library built on top of Tailwind and Radix UI. Supabase \u2014 Backend-as-a-Service platform for authentication, database, and storage. React Router \u2014 Declarative routing for React. React Hook Form \u2014 Easy form handling and validation. Zod \u2014 TypeScript-first schema validation library. Lucide Icons \u2014 Icon set used across the UI. Development Tools \u00b6 TypeScript \u2014 Adds static typing to JavaScript. ESLint \u2014 Linting tool to ensure code quality. Prettier \u2014 Code formatter. eslint-plugin-react-hooks \u2014 Enforces React Hooks rules. eslint-plugin-react-refresh \u2014 Supports React Fast Refresh during development. Vite Plugin React \u2014 Enables React support in Vite. Installation \u00b6 To install all dependencies, run: ```bash npm install pre> mermaid graph TD A[Start] --> B{Is Mermaid Working?} B -- Yes --> C[Awesome!] B -- No --> D[Debug It] D --> B","title":"Dependencies"},{"location":"dependencies/dependencies.html#dependencies","text":"This project uses Node.js and npm for package and build management.","title":"Dependencies"},{"location":"dependencies/dependencies.html#core-dependencies","text":"React \u2014 Frontend library for building UI components. Vite \u2014 Modern frontend build tool. Tailwind CSS \u2014 Utility-first CSS framework for styling. shadcn/ui \u2014 Component library built on top of Tailwind and Radix UI. Supabase \u2014 Backend-as-a-Service platform for authentication, database, and storage. React Router \u2014 Declarative routing for React. React Hook Form \u2014 Easy form handling and validation. Zod \u2014 TypeScript-first schema validation library. Lucide Icons \u2014 Icon set used across the UI.","title":"Core Dependencies"},{"location":"dependencies/dependencies.html#development-tools","text":"TypeScript \u2014 Adds static typing to JavaScript. ESLint \u2014 Linting tool to ensure code quality. Prettier \u2014 Code formatter. eslint-plugin-react-hooks \u2014 Enforces React Hooks rules. eslint-plugin-react-refresh \u2014 Supports React Fast Refresh during development. Vite Plugin React \u2014 Enables React support in Vite.","title":"Development Tools"},{"location":"dependencies/dependencies.html#installation","text":"To install all dependencies, run: ```bash npm install pre> mermaid graph TD A[Start] --> B{Is Mermaid Working?} B -- Yes --> C[Awesome!] B -- No --> D[Debug It] D --> B","title":"Installation"},{"location":"ml_pipeline/requirements.html","text":"\ud83d\udce6 Python Requirements \u00b6 This file lists all required Python packages for the AdHoc_Trader project. These packages are pinned to specific versions for consistent builds. File : requirements.txt \ud83e\uddf1 Core Libraries \u00b6 Package Version Purpose pydantic 2.11.7 Data validation and settings management using Python type annotations. pydantic_core 2.33.2 Low-level core of Pydantic. typing_extensions 4.14.1 Backports for new typing features. typing-inspection 0.4.1 Runtime inspection utilities for types. annotated-types 0.7.0 Defines annotated types to improve Pydantic models. StrEnum 0.4.15 Enum base class that serializes to strings. \ud83c\udf10 Web and API Libraries \u00b6 Package Version Purpose httpx 0.28.1 Async HTTP client. requests 2.32.4 Standard HTTP client. httpcore 1.0.9 Core HTTP engine used by HTTPX. h11 0.16.0 HTTP/1.1 client/server protocol. h2 4.2.0 HTTP/2 protocol support. hyperframe 6.1.0 Frame-based protocol layer for HTTP/2. idna 3.10 Internationalized Domain Names. certifi 2025.7.14 SSL certificates. urllib3 2.5.0 HTTP library used with requests. charset-normalizer 3.4.2 Character encoding auto-detection. sniffio 1.3.1 Async environment sniffing. anyio 4.9.0 Async concurrency library used by HTTPX. websockets 15.0.1 WebSocket support. \ud83d\udd17 Supabase Integration \u00b6 Package Version Purpose supabase 2.17.0 Supabase Python SDK. gotrue 2.12.3 Auth client for Supabase. postgrest 1.1.1 REST API layer over PostgreSQL. realtime 2.6.0 Realtime communication with Supabase. storage3 0.12.0 Supabase storage access. supafunc 0.10.1 Serverless function utilities for Supabase. \ud83d\udcd8 Markdown & Documentation \u00b6 Package Version Purpose mkdocs 1.6.1 Static site generator. mkdocs-material 9.6.16 Material design theme for MkDocs. mkdocs-material-extensions 1.3.1 Extra features for Material theme. mkdocs-get-deps 0.2.0 MkDocs plugin to extract Python dependencies. mkdocs-mermaid2-plugin 1.2.1 Markdown Extension Mermaid.js pymdown-extensions 10.16.1 Markdown extensions (used in Material theme). Markdown 3.8.2 Core Python Markdown parser. ghp-import 2.1.0 Publish MkDocs site to GitHub Pages. \ud83d\udee0\ufe0f Development Tools \u00b6 Package Version Purpose pylint 3.3.7 Code analysis / linter. isort 6.0.1 Sorts imports. astroid 3.3.11 Abstract syntax tree for Python. mccabe 0.7.0 Complexity checker (used by pylint). deprecation 2.1.0 Mark deprecated code. watchdog 6.0.0 File watching utilities. \ud83e\uddf0 Utilities & Config \u00b6 Package Version Purpose dill 0.4.0 Serialize Python objects (better than pickle). click 8.2.2 Command-line utilities. colorama 0.4.6 Colored terminal output. python-dotenv 1.1.1 Loads environment variables from .env. pyyaml 6.0.2 YAML parser. pyyaml_env_tag 1.1 Adds !ENV support to pyyaml. pathspec 0.12.1 Filesystem pattern matching. platformdirs 4.3.8 OS-specific dirs for config/data/cache. mergedeep 1.3.4 Deep merge dictionaries. babel 2.17.0 i18n/l10n tools. paginate 0.5.7 Pagination for large lists. Jinja2 3.1.6 Templating engine. MarkupSafe 3.0.2 Required by Jinja2. six 1.17.0 Python 2/3 compatibility. python-dateutil 2.9.0.post0 Date parsing utilities. Pygments 2.19.2 Syntax highlighting. PyJWT 2.10.1 JSON Web Token library. packaging 25.0 Package version parsing. \u2705 Installation Command \u00b6 To install all dependencies, run: ```bash pip install -r requirements.txt","title":"Requirements"},{"location":"ml_pipeline/requirements.html#python-requirements","text":"This file lists all required Python packages for the AdHoc_Trader project. These packages are pinned to specific versions for consistent builds. File : requirements.txt","title":"\ud83d\udce6 Python Requirements"},{"location":"ml_pipeline/requirements.html#core-libraries","text":"Package Version Purpose pydantic 2.11.7 Data validation and settings management using Python type annotations. pydantic_core 2.33.2 Low-level core of Pydantic. typing_extensions 4.14.1 Backports for new typing features. typing-inspection 0.4.1 Runtime inspection utilities for types. annotated-types 0.7.0 Defines annotated types to improve Pydantic models. StrEnum 0.4.15 Enum base class that serializes to strings.","title":"\ud83e\uddf1 Core Libraries"},{"location":"ml_pipeline/requirements.html#web-and-api-libraries","text":"Package Version Purpose httpx 0.28.1 Async HTTP client. requests 2.32.4 Standard HTTP client. httpcore 1.0.9 Core HTTP engine used by HTTPX. h11 0.16.0 HTTP/1.1 client/server protocol. h2 4.2.0 HTTP/2 protocol support. hyperframe 6.1.0 Frame-based protocol layer for HTTP/2. idna 3.10 Internationalized Domain Names. certifi 2025.7.14 SSL certificates. urllib3 2.5.0 HTTP library used with requests. charset-normalizer 3.4.2 Character encoding auto-detection. sniffio 1.3.1 Async environment sniffing. anyio 4.9.0 Async concurrency library used by HTTPX. websockets 15.0.1 WebSocket support.","title":"\ud83c\udf10 Web and API Libraries"},{"location":"ml_pipeline/requirements.html#supabase-integration","text":"Package Version Purpose supabase 2.17.0 Supabase Python SDK. gotrue 2.12.3 Auth client for Supabase. postgrest 1.1.1 REST API layer over PostgreSQL. realtime 2.6.0 Realtime communication with Supabase. storage3 0.12.0 Supabase storage access. supafunc 0.10.1 Serverless function utilities for Supabase.","title":"\ud83d\udd17 Supabase Integration"},{"location":"ml_pipeline/requirements.html#markdown-documentation","text":"Package Version Purpose mkdocs 1.6.1 Static site generator. mkdocs-material 9.6.16 Material design theme for MkDocs. mkdocs-material-extensions 1.3.1 Extra features for Material theme. mkdocs-get-deps 0.2.0 MkDocs plugin to extract Python dependencies. mkdocs-mermaid2-plugin 1.2.1 Markdown Extension Mermaid.js pymdown-extensions 10.16.1 Markdown extensions (used in Material theme). Markdown 3.8.2 Core Python Markdown parser. ghp-import 2.1.0 Publish MkDocs site to GitHub Pages.","title":"\ud83d\udcd8 Markdown &amp; Documentation"},{"location":"ml_pipeline/requirements.html#development-tools","text":"Package Version Purpose pylint 3.3.7 Code analysis / linter. isort 6.0.1 Sorts imports. astroid 3.3.11 Abstract syntax tree for Python. mccabe 0.7.0 Complexity checker (used by pylint). deprecation 2.1.0 Mark deprecated code. watchdog 6.0.0 File watching utilities.","title":"\ud83d\udee0\ufe0f Development Tools"},{"location":"ml_pipeline/requirements.html#utilities-config","text":"Package Version Purpose dill 0.4.0 Serialize Python objects (better than pickle). click 8.2.2 Command-line utilities. colorama 0.4.6 Colored terminal output. python-dotenv 1.1.1 Loads environment variables from .env. pyyaml 6.0.2 YAML parser. pyyaml_env_tag 1.1 Adds !ENV support to pyyaml. pathspec 0.12.1 Filesystem pattern matching. platformdirs 4.3.8 OS-specific dirs for config/data/cache. mergedeep 1.3.4 Deep merge dictionaries. babel 2.17.0 i18n/l10n tools. paginate 0.5.7 Pagination for large lists. Jinja2 3.1.6 Templating engine. MarkupSafe 3.0.2 Required by Jinja2. six 1.17.0 Python 2/3 compatibility. python-dateutil 2.9.0.post0 Date parsing utilities. Pygments 2.19.2 Syntax highlighting. PyJWT 2.10.1 JSON Web Token library. packaging 25.0 Package version parsing.","title":"\ud83e\uddf0 Utilities &amp; Config"},{"location":"ml_pipeline/requirements.html#installation-command","text":"To install all dependencies, run: ```bash pip install -r requirements.txt","title":"\u2705 Installation Command"},{"location":"ml_pipeline/VSCode/setting.json.html","text":"VSCode Settings Overview \u00b6 These settings are specific to the current workspace. They support both the backend (Python) and frontend (TypeScript + Deno) parts of the project. \u2705 Python Configuration \u00b6 ```jsonc \"python.analysis.extraPaths\": [\"./\"], \"python.envFile\": \"${workspaceFolder}/.env\", \"python.linting.enabled\": true, \"python.linting.pylintEnabled\": true, \"python.linting.lintOnSave\": true, \"python.linting.pylintPath\": \"${workspaceFolder}/venv/Scripts/pylint.exe\" extraPaths: Ensures proper import resolution. envFile: Loads environment variables for Python scripts. pylint: Enabled for code quality. \"deno.enable\": true, \"deno.lint\": true, \"deno.unstable\": true, \"deno.importMap\": \"./import_map.json\", \"files.associations\": { \" /supabase/functions/ /*.ts\": \"typescript\" } Used for Supabase Edge Functions only. If not using Deno across the entire project, scope it to subfolders. Used for Supabase Edge Functions only.","title":"VSCode Settings Overview"},{"location":"ml_pipeline/VSCode/setting.json.html#vscode-settings-overview","text":"These settings are specific to the current workspace. They support both the backend (Python) and frontend (TypeScript + Deno) parts of the project.","title":"VSCode Settings Overview"},{"location":"ml_pipeline/VSCode/setting.json.html#python-configuration","text":"```jsonc \"python.analysis.extraPaths\": [\"./\"], \"python.envFile\": \"${workspaceFolder}/.env\", \"python.linting.enabled\": true, \"python.linting.pylintEnabled\": true, \"python.linting.lintOnSave\": true, \"python.linting.pylintPath\": \"${workspaceFolder}/venv/Scripts/pylint.exe\" extraPaths: Ensures proper import resolution. envFile: Loads environment variables for Python scripts. pylint: Enabled for code quality. \"deno.enable\": true, \"deno.lint\": true, \"deno.unstable\": true, \"deno.importMap\": \"./import_map.json\", \"files.associations\": { \" /supabase/functions/ /*.ts\": \"typescript\" } Used for Supabase Edge Functions only. If not using Deno across the entire project, scope it to subfolders. Used for Supabase Edge Functions only.","title":"\u2705 Python Configuration"},{"location":"ml_pipeline/historical_ingestion/alpha_vantage_client.html","text":"alpha_vanatage_client.py This module provides functionality to fetch daily adjusted stock price data from the Alpha Vantage API. It is used in data ingestion pipelines to retrieve full historical stock data for one or more symbols. \ud83d\udce6 Dependencies requests ml_pipeline.historical_ingestion.config (for ALPHA_VANTAGE_API_KEY) \ud83d\udd27 Functions fetch_daily_adjusted(symbol: str) -> dict Fetches daily adjusted time series data for a given stock ticker symbol. Parameters symbol (str): Ticker symbol of the stock (e.g., \"AAPL\", \"TSLA\"). Returns dict: Time series data keyed by date. Returns an empty dict if the request fails or no data is available. Raises requests.RequestException: If there\u2019s a network or HTTP error. \ud83e\udde0 Example Usage from alpha_vanatage_client import fetch_daily_adjusted data = fetch_daily_adjusted(\"AAPL\") print(data[\"2023-08-01\"]) \ud83d\udcc1 Location bash Copy Edit ml_pipeline/ \u251c\u2500\u2500 historical_ingestion/ \u2502 \u2514\u2500\u2500 alpha_vanatage_client.py","title":"Alpha Vantage Client"},{"location":"ml_pipeline/historical_ingestion/config.py.html","text":"Configuration for Historical Ingestion Pipeline \u00b6 This module provides configuration settings required by the historical data ingestion pipeline. Purpose \u00b6 Loads environment variables from a .env file using python-dotenv . Provides API keys and default symbols to be used by other modules. Environment Variables \u00b6 Variable Description Default ALPHA_VANTAGE_API_KEY API key for Alpha Vantage service None (required) SUPABASE_URL URL endpoint for Supabase project None (required) SUPABASE_KEY Service role key for Supabase None (required) DEFAULT_SYMBOLS Comma-separated list of stock symbols to ingest \"AAPL,MSFT,GOOG\" Usage \u00b6 The variables are loaded at runtime and accessible as module-level constants: from config import ALPHA_VANTAGE_API_KEY, DEFAULT_SYMBOLS Dependencies python-dotenv for loading environment variables from .env.","title":"Config"},{"location":"ml_pipeline/historical_ingestion/config.py.html#configuration-for-historical-ingestion-pipeline","text":"This module provides configuration settings required by the historical data ingestion pipeline.","title":"Configuration for Historical Ingestion Pipeline"},{"location":"ml_pipeline/historical_ingestion/config.py.html#purpose","text":"Loads environment variables from a .env file using python-dotenv . Provides API keys and default symbols to be used by other modules.","title":"Purpose"},{"location":"ml_pipeline/historical_ingestion/config.py.html#environment-variables","text":"Variable Description Default ALPHA_VANTAGE_API_KEY API key for Alpha Vantage service None (required) SUPABASE_URL URL endpoint for Supabase project None (required) SUPABASE_KEY Service role key for Supabase None (required) DEFAULT_SYMBOLS Comma-separated list of stock symbols to ingest \"AAPL,MSFT,GOOG\"","title":"Environment Variables"},{"location":"ml_pipeline/historical_ingestion/config.py.html#usage","text":"The variables are loaded at runtime and accessible as module-level constants: from config import ALPHA_VANTAGE_API_KEY, DEFAULT_SYMBOLS Dependencies python-dotenv for loading environment variables from .env.","title":"Usage"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html","text":"ingest_historical.py Stock Data Normalization Module \u00b6 This module provides functionality to localize and normalize raw stock data from Alpha Vantage for ingestion into a Supabase database. Function: normalize_stock_data(symbol, raw_data) \u00b6 Purpose: Transforms raw daily stock data from Alpha Vantage into a list of normalized dictionaries suitable for database insertion. Arguments \u00b6 symbol ( str ): The stock ticker symbol (e.g., \"AAPL\"). raw_data ( dict ): Raw stock data from Alpha Vantage API, keyed by date strings (e.g., \"2023-07-01\"). Returns \u00b6 list[dict] : A list of normalized records, each with the following fields: symbol ( str ): Stock symbol. date ( str ): ISO8601 timestamp in UTC. open ( float ): Opening price. high ( float ): High price. low ( float ): Low price. close ( float ): Closing price. adjusted_close ( float ): Adjusted closing price. volume ( int ): Trading volume. source ( str ): Data source, hardcoded to \"historical\" . ingested_at ( str ): Timestamp when data was normalized (current UTC time in ISO8601). Error Handling \u00b6 Logs errors if data fields are missing or cannot be converted. Dependencies \u00b6 datetime logging pytz Usage Example \u00b6 ```python from your_module import normalize_stock_data raw_data = {...} # Raw Alpha Vantage data dictionary normalized_rows = normalize_stock_data(\"AAPL\", raw_data)","title":"Ingestion Historical"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#stock-data-normalization-module","text":"This module provides functionality to localize and normalize raw stock data from Alpha Vantage for ingestion into a Supabase database.","title":"Stock Data Normalization Module"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#function-normalize_stock_datasymbol-raw_data","text":"Purpose: Transforms raw daily stock data from Alpha Vantage into a list of normalized dictionaries suitable for database insertion.","title":"Function: normalize_stock_data(symbol, raw_data)"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#arguments","text":"symbol ( str ): The stock ticker symbol (e.g., \"AAPL\"). raw_data ( dict ): Raw stock data from Alpha Vantage API, keyed by date strings (e.g., \"2023-07-01\").","title":"Arguments"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#returns","text":"list[dict] : A list of normalized records, each with the following fields: symbol ( str ): Stock symbol. date ( str ): ISO8601 timestamp in UTC. open ( float ): Opening price. high ( float ): High price. low ( float ): Low price. close ( float ): Closing price. adjusted_close ( float ): Adjusted closing price. volume ( int ): Trading volume. source ( str ): Data source, hardcoded to \"historical\" . ingested_at ( str ): Timestamp when data was normalized (current UTC time in ISO8601).","title":"Returns"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#error-handling","text":"Logs errors if data fields are missing or cannot be converted.","title":"Error Handling"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#dependencies","text":"datetime logging pytz","title":"Dependencies"},{"location":"ml_pipeline/historical_ingestion/ingest_historical.html#usage-example","text":"```python from your_module import normalize_stock_data raw_data = {...} # Raw Alpha Vantage data dictionary normalized_rows = normalize_stock_data(\"AAPL\", raw_data)","title":"Usage Example"},{"location":"ml_pipeline/historical_ingestion/run_pipeline.html","text":"run.pipeline.py \u00b6 This script serves as the entry point for the historical stock data ingestion pipeline. It fetches daily adjusted stock price data for specified stock symbols, normalizes the data, and inserts it into a Supabase database. Main Function: run(symbols) \u00b6 Processes a list of stock symbols by fetching, normalizing, and storing their historical data. Parameters \u00b6 symbols ( list[str] ): List of stock ticker symbols to process (e.g., [\"AAPL\", \"MSFT\"] ). Behavior \u00b6 For each symbol: Logs the start of processing. Fetches daily adjusted data from Alpha Vantage. If no data is returned, logs a warning and skips. Normalizes the raw data. Inserts normalized records into the database. Logs the number of records inserted. Waits 12 seconds between requests to comply with API rate limits. Command Line Usage \u00b6 Run this script from the command line with optional symbols argument: ```bash python run.pipeline.py --symbols AAPL,TSLA,MSFT If no symbols are provided, it defaults to the DEFAULT_SYMBOLS list from the configuration. Logging Uses Python's logging module to output info and warning messages during execution. Dependencies argparse time logging ml_pipeline.historical_ingestion.supabase_client ml_pipeline.historical_ingestion.ingest_historical ml_pipeline.historical_ingestion.alpha_vantage_client ml_pipeline.historical_ingestion.config Notes The 12-second delay between API calls helps avoid hitting Alpha Vantage's rate limits.","title":"Run Pipeline"},{"location":"ml_pipeline/historical_ingestion/run_pipeline.html#runpipelinepy","text":"This script serves as the entry point for the historical stock data ingestion pipeline. It fetches daily adjusted stock price data for specified stock symbols, normalizes the data, and inserts it into a Supabase database.","title":"run.pipeline.py"},{"location":"ml_pipeline/historical_ingestion/run_pipeline.html#main-function-runsymbols","text":"Processes a list of stock symbols by fetching, normalizing, and storing their historical data.","title":"Main Function: run(symbols)"},{"location":"ml_pipeline/historical_ingestion/run_pipeline.html#parameters","text":"symbols ( list[str] ): List of stock ticker symbols to process (e.g., [\"AAPL\", \"MSFT\"] ).","title":"Parameters"},{"location":"ml_pipeline/historical_ingestion/run_pipeline.html#behavior","text":"For each symbol: Logs the start of processing. Fetches daily adjusted data from Alpha Vantage. If no data is returned, logs a warning and skips. Normalizes the raw data. Inserts normalized records into the database. Logs the number of records inserted. Waits 12 seconds between requests to comply with API rate limits.","title":"Behavior"},{"location":"ml_pipeline/historical_ingestion/run_pipeline.html#command-line-usage","text":"Run this script from the command line with optional symbols argument: ```bash python run.pipeline.py --symbols AAPL,TSLA,MSFT If no symbols are provided, it defaults to the DEFAULT_SYMBOLS list from the configuration. Logging Uses Python's logging module to output info and warning messages during execution. Dependencies argparse time logging ml_pipeline.historical_ingestion.supabase_client ml_pipeline.historical_ingestion.ingest_historical ml_pipeline.historical_ingestion.alpha_vantage_client ml_pipeline.historical_ingestion.config Notes The 12-second delay between API calls helps avoid hitting Alpha Vantage's rate limits.","title":"Command Line Usage"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html","text":"supabase_client.py \u00b6 This module provides functionality to interact with Supabase for inserting stock data records into a database. Supabase Client Initialization \u00b6 Uses the create_client method from the Supabase Python SDK to create a client instance. Credentials ( SUPABASE_URL and SUPABASE_KEY ) are imported from the configuration module. Function: insert_stock_data(records) \u00b6 Inserts stock data records into the Supabase stock_prices table in batches. Parameters \u00b6 records ( list[dict] ): List of dictionaries, each representing a stock data row to insert. Behavior \u00b6 If records is empty or None , the function returns immediately without action. Inserts data in batches of 100 records to handle large datasets efficiently. Catches and logs errors such as HTTP errors, value errors, or type errors during insertion. Exceptions \u00b6 Raises ValueError if input is not a list (implicitly checked). Handles Supabase-specific errors (via HTTPError) gracefully by printing an error message. Dependencies \u00b6 httpx.HTTPError supabase (Python SDK) Configuration variables SUPABASE_URL , SUPABASE_KEY Usage \u00b6 This function is typically called by the ingestion pipeline after data normalization to persist stock price records. Notes \u00b6 Adjust batch size if needed depending on API limits or performance considerations. Replace generic error handling with specific Supabase exceptions if available for more granular control.","title":"Supabase Client"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#supabase_clientpy","text":"This module provides functionality to interact with Supabase for inserting stock data records into a database.","title":"supabase_client.py"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#supabase-client-initialization","text":"Uses the create_client method from the Supabase Python SDK to create a client instance. Credentials ( SUPABASE_URL and SUPABASE_KEY ) are imported from the configuration module.","title":"Supabase Client Initialization"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#function-insert_stock_datarecords","text":"Inserts stock data records into the Supabase stock_prices table in batches.","title":"Function: insert_stock_data(records)"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#parameters","text":"records ( list[dict] ): List of dictionaries, each representing a stock data row to insert.","title":"Parameters"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#behavior","text":"If records is empty or None , the function returns immediately without action. Inserts data in batches of 100 records to handle large datasets efficiently. Catches and logs errors such as HTTP errors, value errors, or type errors during insertion.","title":"Behavior"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#exceptions","text":"Raises ValueError if input is not a list (implicitly checked). Handles Supabase-specific errors (via HTTPError) gracefully by printing an error message.","title":"Exceptions"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#dependencies","text":"httpx.HTTPError supabase (Python SDK) Configuration variables SUPABASE_URL , SUPABASE_KEY","title":"Dependencies"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#usage","text":"This function is typically called by the ingestion pipeline after data normalization to persist stock price records.","title":"Usage"},{"location":"ml_pipeline/historical_ingestion/supabase_client.html#notes","text":"Adjust batch size if needed depending on API limits or performance considerations. Replace generic error handling with specific Supabase exceptions if available for more granular control.","title":"Notes"},{"location":"ml_pipeline/historical_ingestion/utils.html","text":"Utils Module \u00b6 This module provides utility functions used during the data ingestion process. It includes: Logging configuration A retry decorator for fault-tolerant operations Logging Configuration \u00b6 The module configures logging to output messages to both a file ( ingestion.log ) and the console. ```python import logging logging.basicConfig( level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", handlers=[logging.FileHandler(\"ingestion.log\"), logging.StreamHandler()], ) Logging Format Each log entry follows this format: ruby Copy Edit YYYY-MM-DD HH:MM:SS [LEVEL] Message retry Decorator The retry decorator allows retrying a function multiple times if it raises an exception. python Copy Edit def retry(attempts=3, delay=5): def decorator(func): @wraps(func) def wrapper( args, kwargs): for i in range(attempts): try: return func( args, **kwargs) except Exception as e: logging.warning( f\"Retry {i+1}/{attempts} for {func. name } failed: {e}\" ) time.sleep(delay) raise Exception(f\"All {attempts} retries failed.\") return wrapper return decorator Parameters attempts (int): Number of retry attempts (default is 3). delay (int): Delay (in seconds) between retries (default is 5). Usage python Copy Edit @retry(attempts=5, delay=2) def fetch_data(): # Your potentially failing code pass This will try to execute fetch_data() up to 5 times, waiting 2 seconds between attempts. Example Output yaml Copy Edit 2025-08-04 17:00:00 [WARNING] Retry 1/3 for fetch_data failed: TimeoutError 2025-08-04 17:00:05 [WARNING] Retry 2/3 for fetch_data failed: TimeoutError 2025-08-04 17:00:10 [WARNING] Retry 3/3 for fetch_data failed: TimeoutError","title":"Utils"},{"location":"ml_pipeline/historical_ingestion/utils.html#utils-module","text":"This module provides utility functions used during the data ingestion process. It includes: Logging configuration A retry decorator for fault-tolerant operations","title":"Utils Module"},{"location":"ml_pipeline/historical_ingestion/utils.html#logging-configuration","text":"The module configures logging to output messages to both a file ( ingestion.log ) and the console. ```python import logging logging.basicConfig( level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", handlers=[logging.FileHandler(\"ingestion.log\"), logging.StreamHandler()], ) Logging Format Each log entry follows this format: ruby Copy Edit YYYY-MM-DD HH:MM:SS [LEVEL] Message retry Decorator The retry decorator allows retrying a function multiple times if it raises an exception. python Copy Edit def retry(attempts=3, delay=5): def decorator(func): @wraps(func) def wrapper( args, kwargs): for i in range(attempts): try: return func( args, **kwargs) except Exception as e: logging.warning( f\"Retry {i+1}/{attempts} for {func. name } failed: {e}\" ) time.sleep(delay) raise Exception(f\"All {attempts} retries failed.\") return wrapper return decorator Parameters attempts (int): Number of retry attempts (default is 3). delay (int): Delay (in seconds) between retries (default is 5). Usage python Copy Edit @retry(attempts=5, delay=2) def fetch_data(): # Your potentially failing code pass This will try to execute fetch_data() up to 5 times, waiting 2 seconds between attempts. Example Output yaml Copy Edit 2025-08-04 17:00:00 [WARNING] Retry 1/3 for fetch_data failed: TimeoutError 2025-08-04 17:00:05 [WARNING] Retry 2/3 for fetch_data failed: TimeoutError 2025-08-04 17:00:10 [WARNING] Retry 3/3 for fetch_data failed: TimeoutError","title":"Logging Configuration"},{"location":"ml_pipeline/src/dl/lstm_model.html","text":"","title":"LSTM Model"},{"location":"ml_pipeline/src/ml/data_fetcher.html","text":"ml_pipeline/src/ml/data_fetcher.md markdown \ud83d\udcca data_fetcher.py \u00b6 This module fetches intraday stock price data from the Alpha Vantage API and uploads it to Supabase. It also prints the latest 5 rows of data for validation. \ud83d\udcc1 Location \u00b6 src/ml/data_fetcher.py Run via: python -m src.ml.data_fetcher --- ## \ud83d\udcc8 Process Flow Process Flow \u00b6 flowchart TD A[Start] --> B[Load ALPHA_VANTAGE_KEY from .env] B --> C[Make HTTP request to Alpha Vantage API] C --> D[Parse JSON response] D --> E[Convert to DataFrame] E --> F[Clean and sort data] F --> G[Upload to Supabase] G --> H[Print last 5 rows] Function: fetch_stock_data(...) Fetches intraday time series stock data for a given symbol and returns it as a pandas DataFrame. Parameters ticker (str): Stock symbol to query (e.g. \"AAPL\"). interval (str, default: \"60min\"): Time interval for intraday data. Options: \"1min\", \"5min\", \"15min\", \"30min\", \"60min\". outputsize (str, default: \"compact\"): \"compact\" = last 100 data points, \"full\" = entire history. Returns pd.DataFrame: Cleaned, chronologically sorted stock price data with columns: open, high, low, close, volume If the API call fails or the data is invalid, returns an empty DataFrame. \ud83d\udce6 Dependencies pandas requests python-dotenv Local module: supabase_uploader.upload_to_supabase() Environment Variables These must be defined in a .env file at the project root: ALPHA_VANTAGE_KEY: Your Alpha Vantage API key. Main Script Behavior When run directly (e.g., via CLI): $ python -m src.ml.data_fetcher It will: Fetch 60min intraday data for \"AAPL\" Upload the result to Supabase Print the last 5 rows of the resulting DataFrame \u26a0\ufe0f Error Handling Gracefully handles and logs: \u274c Missing API key \u274c HTTP/network failures \u274c Malformed or unexpected API responses \ud83d\udce4 Example Usage $ python -m src.ml.data_fetcher \ud83d\udce1 Fetching data for AAPL... \u2705 100 rows fetched for AAPL open high low close volume ... ... ... ... ... \ud83e\udde9 Related Files supabase_uploader.py: Handles uploading the DataFrame to Supabase. .env: Must contain your ALPHA_VANTAGE_KEY. \u2705 Notes Alpha Vantage free tier limits: 5 API calls per minute, 500 per day. Best used in automated data pipelines or on-demand analysis.","title":"Data Fetcher"},{"location":"ml_pipeline/src/ml/data_fetcher.html#data_fetcherpy","text":"This module fetches intraday stock price data from the Alpha Vantage API and uploads it to Supabase. It also prints the latest 5 rows of data for validation.","title":"\ud83d\udcca data_fetcher.py"},{"location":"ml_pipeline/src/ml/data_fetcher.html#location","text":"src/ml/data_fetcher.py Run via: python -m src.ml.data_fetcher --- ## \ud83d\udcc8 Process Flow","title":"\ud83d\udcc1 Location"},{"location":"ml_pipeline/src/ml/data_fetcher.html#process-flow","text":"flowchart TD A[Start] --> B[Load ALPHA_VANTAGE_KEY from .env] B --> C[Make HTTP request to Alpha Vantage API] C --> D[Parse JSON response] D --> E[Convert to DataFrame] E --> F[Clean and sort data] F --> G[Upload to Supabase] G --> H[Print last 5 rows] Function: fetch_stock_data(...) Fetches intraday time series stock data for a given symbol and returns it as a pandas DataFrame. Parameters ticker (str): Stock symbol to query (e.g. \"AAPL\"). interval (str, default: \"60min\"): Time interval for intraday data. Options: \"1min\", \"5min\", \"15min\", \"30min\", \"60min\". outputsize (str, default: \"compact\"): \"compact\" = last 100 data points, \"full\" = entire history. Returns pd.DataFrame: Cleaned, chronologically sorted stock price data with columns: open, high, low, close, volume If the API call fails or the data is invalid, returns an empty DataFrame. \ud83d\udce6 Dependencies pandas requests python-dotenv Local module: supabase_uploader.upload_to_supabase() Environment Variables These must be defined in a .env file at the project root: ALPHA_VANTAGE_KEY: Your Alpha Vantage API key. Main Script Behavior When run directly (e.g., via CLI): $ python -m src.ml.data_fetcher It will: Fetch 60min intraday data for \"AAPL\" Upload the result to Supabase Print the last 5 rows of the resulting DataFrame \u26a0\ufe0f Error Handling Gracefully handles and logs: \u274c Missing API key \u274c HTTP/network failures \u274c Malformed or unexpected API responses \ud83d\udce4 Example Usage $ python -m src.ml.data_fetcher \ud83d\udce1 Fetching data for AAPL... \u2705 100 rows fetched for AAPL open high low close volume ... ... ... ... ... \ud83e\udde9 Related Files supabase_uploader.py: Handles uploading the DataFrame to Supabase. .env: Must contain your ALPHA_VANTAGE_KEY. \u2705 Notes Alpha Vantage free tier limits: 5 API calls per minute, 500 per day. Best used in automated data pipelines or on-demand analysis.","title":"Process Flow"},{"location":"ml_pipeline/src/ml/feature_engineer.html","text":"feature_engineer.py \u00b6 This module provides the featured enginering for stock price time series data. It uses pandas-ta to compute a variety of technical indicators commonly used in algorithmic trading and quantitative analysis. \ud83d\udcc1 Location \u00b6 src/ml/feature_engineer.py Function: feature_engineer (df: pd.DataFrame) -> pd.DataFrame \u00b6 Description \u00b6 Enhances the input DataFrame with multiple technical indicators and returns the transformed version with new features. Parameters \u00b6 df ( pd.DataFrame ): A DataFrame indexed by datetime with at least the following columns: \"open\" \"high\" \"low\" \"close\" \"volume\" Returns \u00b6 pd.DataFrame : A new DataFrame including: Original OHLCV columns Appended technical indicators Cleaned to remove any NaN rows caused by rolling windows Raises \u00b6 ValueError : If the input DataFrame is empty. \ud83d\udcca Technical Indicators Used \u00b6 Indicator Function Purpose SMA ta.sma(length=20) Simple moving average EMA ta.ema(length=20) Exponential moving average RSI ta.rsi(length=14) Measures price momentum MACD ta.macd() Trend-following momentum BBANDS ta.bbands(length=20) Bollinger Bands (volatility) OBV ta.obv() On-Balance Volume ADX ta.adx(length=14) Average Directional Index \u2705 Output Example \u00b6 After feature engineering: - Output DataFrame might contain 40+ columns (depending on the number of sub-indicators from MACD, BBANDS, etc.) - All NaN rows from the initial rolling period are removed - Prints: \u2705 Engineered features: 42 columns, 85 rows. \ud83e\udde9 Dependencies \u00b6 pandas pandas-ta (must be installed separately) Install with: pip install pandas-ta \ud83e\uddea Example Usage import pandas as pd from src.ml.engineer_features import engineer_features df = pd.read_csv(\"AAPL_60min.csv\", index_col=0, parse_dates=True) df = engineer_features(df) print(df.head()) ***** **Notes** **Be sure to run this on pre-cleaned stock price data with datetime index** If using Supabase or another database downstream, consider filtering/flattening the columns for compatibility. Missing index format or volume column will break certain indicators. --- ## Process Flow --- ```mermaid flowchart TD A[Start: Input DataFrame] --> B[Its Dataframe empty] B -- Yes --> Z[Raise Value Error] B -- No --> C[Copy DataFrame] C --> D{[Is Index Datetime]} D -- No --> E[Convert Index to Datetime] D -- Yes --> F[Proceed] E --> F F --> G[Apply SMA (Length=20)] G --> H[Apply EMA (Length=20)] H --> I[Apply RSI (Length=14)] I --> J[Apply MACD] J --> K[Apply Bollinger Bands (Length=20)] K --> L[Apply OBV] L --> M[Apply ADX (Length=14)] M --> N[Drop NaN rows] N --> O[Print Shape Info] O --> P[Return DataFrame] --- ```mermaid flowchart TD A[Start: Input DataFrame] --> B{Is DataFrame empty?} B -- Yes --> Z[Raise ValueError] B -- No --> C[Copy DataFrame] C --> D{Is Index Datetime?} D -- No --> E[Convert Index to Datetime] D -- Yes --> F[Proceed] E --> F F --> G[Apply SMA (Length=20)] G --> H[Apply EMA (Length=20)] H --> I[Apply RSI (Length=14)] I --> J[Apply MACD] J --> K[Apply Bollinger Bands (Length=20)] K --> L[Apply OBV] L --> M[Apply ADX (Length=14)] M --> N[Drop NaN rows] N --> O[Print Shape Info] O --> P[Return DataFrame]","title":"Feature Engineering"},{"location":"ml_pipeline/src/ml/feature_engineer.html#feature_engineerpy","text":"This module provides the featured enginering for stock price time series data. It uses pandas-ta to compute a variety of technical indicators commonly used in algorithmic trading and quantitative analysis.","title":"feature_engineer.py"},{"location":"ml_pipeline/src/ml/feature_engineer.html#location","text":"src/ml/feature_engineer.py","title":"\ud83d\udcc1 Location"},{"location":"ml_pipeline/src/ml/feature_engineer.html#function-feature_engineer-df-pddataframe-pddataframe","text":"","title":"Function: feature_engineer (df: pd.DataFrame) -&gt; pd.DataFrame"},{"location":"ml_pipeline/src/ml/feature_engineer.html#description","text":"Enhances the input DataFrame with multiple technical indicators and returns the transformed version with new features.","title":"Description"},{"location":"ml_pipeline/src/ml/feature_engineer.html#parameters","text":"df ( pd.DataFrame ): A DataFrame indexed by datetime with at least the following columns: \"open\" \"high\" \"low\" \"close\" \"volume\"","title":"Parameters"},{"location":"ml_pipeline/src/ml/feature_engineer.html#returns","text":"pd.DataFrame : A new DataFrame including: Original OHLCV columns Appended technical indicators Cleaned to remove any NaN rows caused by rolling windows","title":"Returns"},{"location":"ml_pipeline/src/ml/feature_engineer.html#raises","text":"ValueError : If the input DataFrame is empty.","title":"Raises"},{"location":"ml_pipeline/src/ml/feature_engineer.html#technical-indicators-used","text":"Indicator Function Purpose SMA ta.sma(length=20) Simple moving average EMA ta.ema(length=20) Exponential moving average RSI ta.rsi(length=14) Measures price momentum MACD ta.macd() Trend-following momentum BBANDS ta.bbands(length=20) Bollinger Bands (volatility) OBV ta.obv() On-Balance Volume ADX ta.adx(length=14) Average Directional Index","title":"\ud83d\udcca Technical Indicators Used"},{"location":"ml_pipeline/src/ml/feature_engineer.html#output-example","text":"After feature engineering: - Output DataFrame might contain 40+ columns (depending on the number of sub-indicators from MACD, BBANDS, etc.) - All NaN rows from the initial rolling period are removed - Prints: \u2705 Engineered features: 42 columns, 85 rows.","title":"\u2705 Output Example"},{"location":"ml_pipeline/src/ml/feature_engineer.html#dependencies","text":"pandas pandas-ta (must be installed separately) Install with: pip install pandas-ta \ud83e\uddea Example Usage import pandas as pd from src.ml.engineer_features import engineer_features df = pd.read_csv(\"AAPL_60min.csv\", index_col=0, parse_dates=True) df = engineer_features(df) print(df.head()) ***** **Notes** **Be sure to run this on pre-cleaned stock price data with datetime index** If using Supabase or another database downstream, consider filtering/flattening the columns for compatibility. Missing index format or volume column will break certain indicators. --- ## Process Flow --- ```mermaid flowchart TD A[Start: Input DataFrame] --> B[Its Dataframe empty] B -- Yes --> Z[Raise Value Error] B -- No --> C[Copy DataFrame] C --> D{[Is Index Datetime]} D -- No --> E[Convert Index to Datetime] D -- Yes --> F[Proceed] E --> F F --> G[Apply SMA (Length=20)] G --> H[Apply EMA (Length=20)] H --> I[Apply RSI (Length=14)] I --> J[Apply MACD] J --> K[Apply Bollinger Bands (Length=20)] K --> L[Apply OBV] L --> M[Apply ADX (Length=14)] M --> N[Drop NaN rows] N --> O[Print Shape Info] O --> P[Return DataFrame] --- ```mermaid flowchart TD A[Start: Input DataFrame] --> B{Is DataFrame empty?} B -- Yes --> Z[Raise ValueError] B -- No --> C[Copy DataFrame] C --> D{Is Index Datetime?} D -- No --> E[Convert Index to Datetime] D -- Yes --> F[Proceed] E --> F F --> G[Apply SMA (Length=20)] G --> H[Apply EMA (Length=20)] H --> I[Apply RSI (Length=14)] I --> J[Apply MACD] J --> K[Apply Bollinger Bands (Length=20)] K --> L[Apply OBV] L --> M[Apply ADX (Length=14)] M --> N[Drop NaN rows] N --> O[Print Shape Info] O --> P[Return DataFrame]","title":"\ud83e\udde9 Dependencies"},{"location":"ml_pipeline/src/ml/predictor.html","text":"","title":"Predictor"},{"location":"ml_pipeline/src/ml/supabase_uploader.html","text":"supabase_uploader.py \u00b6 \ud83d\udce1 Module for uploading stock market data to Supabase \ud83d\udcc1 Location \u00b6 src/ml/supabase_uploader.py \ud83d\udcc4 Description \u00b6 This module: - Connects to your Supabase database using credentials from .env - Accepts a Pandas DataFrame of stock price data - Prepares and formats the data - Uploads it to the stock_prices table using upsert behavior in batches \u2699\ufe0f Environment Variables Required \u00b6 Variable Name Description SUPABASE_URL Your Supabase project API URL SUPABASE_SERVICE_ROLE Your Supabase service role key .env file example: ```env SUPABASE_URL=https://your-project.supabase.co SUPABASE_SERVICE_ROLE=your-secret-service-role-key \ud83e\udde0 Exception python Copy Edit class SupabaseUploadError(Exception) Raised when a data upload attempt to Supabase fails. \ud83d\ude80 Function: upload_to_supabase(df: pd.DataFrame, symbol: str) -> None Description Uploads stock price data to the stock_prices table in Supabase. Parameters Name Type Description df pd.DataFrame DataFrame containing stock data with datetime index symbol str Ticker symbol to label the data (e.g., \"AAPL\") Returns None \u2014 Upload is done via side effects (upsert to Supabase) Raises SupabaseUploadError if: the API returns an invalid response upload fails due to any known issue ValueError if Supabase credentials are missing \ud83e\uddf1 Data Expectations Input df (before processing) Must have a datetime index and the following columns: open high low close volume Output Data Format (after processing): timestamp (converted from index) open, high, low, close, volume symbol (added per function argument) \ud83d\udd01 Upload Process Uploads data in chunks of 100 records Uses upsert() to avoid duplicate entries Timestamps are converted to ISO 8601 format \ud83e\uddea Test Runner You can test the uploader by running the file directly: bash Copy Edit python -m src.ml.supabase_uploader This simulates one row of data for AAPL and uploads it. \ud83e\udde9 Dependencies pandas supabase-py dotenv requests logging Install with: bash Copy Edit pip install pandas python-dotenv supabase requests \u2705 Logging Example If successful: pgsql Copy Edit \u2705 Uploaded 125 rows for AAPL to Supabase. If failed: vbnet Copy Edit ERROR:root:Upload failed due to known error: ... \ud83d\udd12 Security Note Never expose your SUPABASE_SERVICE_ROLE in frontend or public repos. It has admin-level permissions. Store securely. \ud83d\udee0\ufe0f Recommended Improvements Add retry logic with exponential backoff (wrap with retry decorator) Add schema validation before upload (e.g., with Pydantic or Marshmallow) \ud83d\uddc2\ufe0f Related Modules data_fetcher.py \u2192 Fetches stock data engineer_features.py \u2192 Adds technical indicators supabase_client.py \u2192 Alternative insert method for historical data python Copy Edit","title":"Supabase Uploader"},{"location":"ml_pipeline/src/ml/supabase_uploader.html#supabase_uploaderpy","text":"\ud83d\udce1 Module for uploading stock market data to Supabase","title":"supabase_uploader.py"},{"location":"ml_pipeline/src/ml/supabase_uploader.html#location","text":"src/ml/supabase_uploader.py","title":"\ud83d\udcc1 Location"},{"location":"ml_pipeline/src/ml/supabase_uploader.html#description","text":"This module: - Connects to your Supabase database using credentials from .env - Accepts a Pandas DataFrame of stock price data - Prepares and formats the data - Uploads it to the stock_prices table using upsert behavior in batches","title":"\ud83d\udcc4 Description"},{"location":"ml_pipeline/src/ml/supabase_uploader.html#environment-variables-required","text":"Variable Name Description SUPABASE_URL Your Supabase project API URL SUPABASE_SERVICE_ROLE Your Supabase service role key .env file example: ```env SUPABASE_URL=https://your-project.supabase.co SUPABASE_SERVICE_ROLE=your-secret-service-role-key \ud83e\udde0 Exception python Copy Edit class SupabaseUploadError(Exception) Raised when a data upload attempt to Supabase fails. \ud83d\ude80 Function: upload_to_supabase(df: pd.DataFrame, symbol: str) -> None Description Uploads stock price data to the stock_prices table in Supabase. Parameters Name Type Description df pd.DataFrame DataFrame containing stock data with datetime index symbol str Ticker symbol to label the data (e.g., \"AAPL\") Returns None \u2014 Upload is done via side effects (upsert to Supabase) Raises SupabaseUploadError if: the API returns an invalid response upload fails due to any known issue ValueError if Supabase credentials are missing \ud83e\uddf1 Data Expectations Input df (before processing) Must have a datetime index and the following columns: open high low close volume Output Data Format (after processing): timestamp (converted from index) open, high, low, close, volume symbol (added per function argument) \ud83d\udd01 Upload Process Uploads data in chunks of 100 records Uses upsert() to avoid duplicate entries Timestamps are converted to ISO 8601 format \ud83e\uddea Test Runner You can test the uploader by running the file directly: bash Copy Edit python -m src.ml.supabase_uploader This simulates one row of data for AAPL and uploads it. \ud83e\udde9 Dependencies pandas supabase-py dotenv requests logging Install with: bash Copy Edit pip install pandas python-dotenv supabase requests \u2705 Logging Example If successful: pgsql Copy Edit \u2705 Uploaded 125 rows for AAPL to Supabase. If failed: vbnet Copy Edit ERROR:root:Upload failed due to known error: ... \ud83d\udd12 Security Note Never expose your SUPABASE_SERVICE_ROLE in frontend or public repos. It has admin-level permissions. Store securely. \ud83d\udee0\ufe0f Recommended Improvements Add retry logic with exponential backoff (wrap with retry decorator) Add schema validation before upload (e.g., with Pydantic or Marshmallow) \ud83d\uddc2\ufe0f Related Modules data_fetcher.py \u2192 Fetches stock data engineer_features.py \u2192 Adds technical indicators supabase_client.py \u2192 Alternative insert method for historical data python Copy Edit","title":"\u2699\ufe0f Environment Variables Required"},{"location":"ml_pipeline/src/ml/train_model.html","text":"","title":"Training Model"},{"location":"ml_pipeline/test/test_normalization.html","text":"Test: test_normalize_stock_data \u00b6 This test module verifies the correctness of the normalize_stock_data function used in the historical data ingestion pipeline. Tested Function \u00b6 ```python from ingest_historical_data import normalize_stock_data The function normalize_stock_data(symbol, raw_data) is expected to normalize historical stock price data into a structured format. Test Function python Copy Edit def test_normalize_stock_data(): raw = { \"2024-07-25\": { \"1. open\": \"200.00\", \"2. high\": \"205.00\", \"3. low\": \"198.00\", \"4. close\": \"202.00\", \"5. adjusted close\": \"202.00\", \"6. volume\": \"15000000\", } } symbol = \"TEST\" result = normalize_stock_data(symbol, raw) assert len(result) == 1 row = result[0] assert row[\"symbol\"] == \"TEST\" assert row[\"open\"] == 200.00 assert row[\"adjusted_close\"] == 202.00 assert \"date\" in row Test Explanation Input: symbol: \"TEST\" raw: A dictionary mimicking Alpha Vantage's historical daily price format. Expected Output: A list with one normalized dictionary containing: \"symbol\" key matching \"TEST\" \"open\" price correctly parsed to float \"adjusted_close\" correctly extracted A \"date\" field present Assertions Assertion Description assert len(result) == 1 Confirms a single row is returned assert row[\"symbol\"] == \"TEST\" Ensures the symbol is preserved assert row[\"open\"] == 200.00 Confirms the open price is correctly parsed assert row[\"adjusted_close\"] == 202.00 Ensures adjusted close is correct assert \"date\" in row Confirms a date field exists in the normalized row Notes This unit test is intended to verify that the transformation logic applied to historical stock data conforms to expected standards. It should be run using a test runner like pytest. Example Usage bash Copy Edit pytest test_normalization.py vbnet Copy Edit","title":"Test Normalization"},{"location":"ml_pipeline/test/test_normalization.html#test-test_normalize_stock_data","text":"This test module verifies the correctness of the normalize_stock_data function used in the historical data ingestion pipeline.","title":"Test: test_normalize_stock_data"},{"location":"ml_pipeline/test/test_normalization.html#tested-function","text":"```python from ingest_historical_data import normalize_stock_data The function normalize_stock_data(symbol, raw_data) is expected to normalize historical stock price data into a structured format. Test Function python Copy Edit def test_normalize_stock_data(): raw = { \"2024-07-25\": { \"1. open\": \"200.00\", \"2. high\": \"205.00\", \"3. low\": \"198.00\", \"4. close\": \"202.00\", \"5. adjusted close\": \"202.00\", \"6. volume\": \"15000000\", } } symbol = \"TEST\" result = normalize_stock_data(symbol, raw) assert len(result) == 1 row = result[0] assert row[\"symbol\"] == \"TEST\" assert row[\"open\"] == 200.00 assert row[\"adjusted_close\"] == 202.00 assert \"date\" in row Test Explanation Input: symbol: \"TEST\" raw: A dictionary mimicking Alpha Vantage's historical daily price format. Expected Output: A list with one normalized dictionary containing: \"symbol\" key matching \"TEST\" \"open\" price correctly parsed to float \"adjusted_close\" correctly extracted A \"date\" field present Assertions Assertion Description assert len(result) == 1 Confirms a single row is returned assert row[\"symbol\"] == \"TEST\" Ensures the symbol is preserved assert row[\"open\"] == 200.00 Confirms the open price is correctly parsed assert row[\"adjusted_close\"] == 202.00 Ensures adjusted close is correct assert \"date\" in row Confirms a date field exists in the normalized row Notes This unit test is intended to verify that the transformation logic applied to historical stock data conforms to expected standards. It should be run using a test runner like pytest. Example Usage bash Copy Edit pytest test_normalization.py vbnet Copy Edit","title":"Tested Function"}]}